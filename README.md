# awesome-speech-emotion-recognition

[toc]

### 2024 papers

#### InterSpeech 2024

##### Corpora-based Approaches in Automatic Emotion Recognition

- Reinforcement Learning based Data Augmentation for Noise Robust Speech Emotion Recognition
- Unsupervised Domain Adaptation for Speech Emotion Recognition using K-Nearest Neighbors Voice Conversion
- Confidence-aware Hypothesis Transfer Networks for Source-Free Cross-Corpus Speech Emotion Recognition
- An Effective Local Prototypical Mapping Network for Speech Emotion Recognition
- Speech Emotion Recognition with Multi-level Acoustic and Semantic Information Extraction and Interaction
- Boosting Cross-Corpus Speech Emotion Recognition using CycleGAN with Contrastive Learning

##### Emotion Recognition: Resources and Benchmarks

- SER Evals: In-domain and Out-of-domain benchmarking for speech emotion recognition [code](https://github.com/spaghettiSystems/serval)
- EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark [code](https://github.com/emo-box/EmoBox)
- INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of Progress in Speech Emotion Recognition
- What Does it Take to Generalize SER Model Across Datasets? A Comprehensive Benchmark
- WHiSER: White House Tapes Speech Emotion Recognition Corpus [data](https://github.com/msplabresearch/WHiSER)
- Evaluating Transformer-Enhanced Deep Reinforcement Learning for Speech Emotion Recognition
- SAMSEMO: New dataset for multilingual and multimodal emotion recognition [data](https://github.com/samsungnlp/samsemo)
- Emo-bias: A Large Scale Evaluation of Social Bias on Speech Emotion Recognition

##### Accented Speech, Prosodic Features, Dialect, Emotion, Sound Classification

- Cross-modal Features Interaction-and-Aggregation Network with Self-consistency Training for Speech Emotion Recognition
- Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging Co-Attention Cues in Multitask Learning  [code](https://github.com/NLP-SBILAB/CAMuLeNet)
- SELM: Enhancing Speech Emotion Recognition for Out-of-Domain Scenarios

##### Speech Emotion Recognition

- ExHuBERT: Enhancing HuBERT Through Block Extension and Fine-Tuning on 37 Emotion Datasets [code](https://huggingface.co/amiriparian/ExHuBERT/tree/main)
- Dataset-Distillation Generative Model for Speech Emotion Recognition 
- DropFormer: A Dynamic Noise-Dropping Transformer for Speech Emotion Recognition
- From Text to Emotion: Unveiling the Emotion Annotation Capabilities of LLMs [code](https://github.com/chailab-umich/GPT-4-Emotion-Annotation)

##### Topics in Paralinguistics

- Emotion-Aware Speech Self-Supervised Representation Learning with Intensity Knowledge 

##### Emotion Recognition: Fairness, Variability, Uncertainty

- Dual-Constrained Dynamical Neural ODEs for Ambiguity-aware Continuous Emotion Prediction [code](https://github.com/JingyaoWU66/CD-NODE-gamma)
- An Inter-Speaker Fairness-Aware Speech Emotion Regression Framework
- The Whole Is Bigger Than the Sum of Its Parts: Modeling Individual Annotators to Capture Emotional Variability [code](https://github.com/chailab-umich/ModelingIndividualEvaluators)
- Iterative Prototype Refinement for Ambiguous Speech Emotion Recognition
- An Investigation of Group versus Individual Fairness in Perceptually Fair Speech Emotion Recognition
- Are you sure? Analysing Uncertainty Quantification Approaches for Real-world Speech Emotion Recognition [code](https://github.com/audeering/ser-uncertainty-quantification)
- Speech emotion recognition with deep learning beamforming on a distant human-robot interaction scenario

##### New Avenues in Emotion Recognition

- Can Modelling Inter-Rater Ambiguity Lead To Noise-Robust Continuous Emotion Predictions?
- MFDR: Multiple-stage Fusion and Dynamically Refined Network for Multimodal Emotion Recognition
- Multimodal Fusion of Music Theory-Inspired and Self-Supervised Representations for Improved Emotion Recognition
- Enrolment-based personalisation for improving individual-level fairness in speech emotion recognition [code](https://github.com/ATriantafyllopoulos/enrollment-personalization)
- Keep, Delete, or Substitute: Frame Selection Strategy for Noise-Robust Speech Emotion Recognition
- Hierarchical Distribution Adaptation for Unsupervised Cross-corpus Speech Emotion Recognition

##### Spoken Dialogue Systems and Conversational Analysis

- MM-NodeFormer: Node Transformer Multimodal Fusion for Emotion Recognition in Conversation
- Emotional Cues Extraction and Fusion for Multi-modal Emotion Prediction and Recognition in Conversation

##### Speech Type Classification

- E-ODN: An Emotion Open Deep Network for Generalised and Adaptive Speech Emotion Recognition

##### Multimodal Paralinguistics

- LoRA-MER: Low-Rank Adaptation of Pre-Trained Speech Models for Multimodal Emotion Recognition Using Mutual Information [code]( https://github.com/caiyunrui/LoRA-MER)
- Enhancing Modal Fusion by Alignment and Label Matching for Multimodal Emotion Recognition [code](https://github.com/ASolitaryMan/Foal-Net)
- Enhancing Multimodal Emotion Recognition through ASR Error Compensation and LLM Fine-Tuning
- Bridging Emotions Across Languages: Low Rank Adaptation for Multilingual Speech Emotion Recognition

##### Automatic Emotion Recognition

- A Layer-Anchoring Strategy for Enhancing Cross-Lingual Speech Emotion Recognition
- Are Paralinguistic Representations all that is needed for Speech Emotion Recognition? [code](https://github.com/orchidchetiaphukan/ParalinguisticSER)
- MFSN: Multi-perspective Fusion Search Network For Pre-training Knowledge in Speech Emotion Recognition
- Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations

#### ICASSP 2024

##### speech

- Learning Arousal-Valence Representation from Categorical Emotion Labels of Speech  [code](https://github.com/ETZET/SpeechEmotionAVLearning)

- TRUST-SER: On The Trustworthiness Of Fine-Tuning Pre-Trained Speech Embeddings For Speech Emotion Recognition [paper](https://arxiv.org/pdf/2305.11229) [code](https://github.com/usc-sail/trust-ser)
- Emohrnet: High-Resolution Neural Network Based Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10446976)
- Parameter Efficient Finetuning for Speech Emotion Recognition and Domain Adaptation [paper](https://arxiv.org/pdf/2402.11747)
- Investigating Salient Representations and Label Variance in Dimensional Speech Emotion Analysis [paper](https://arxiv.org/html/2312.16180v1)
- Adaptive Speech Emotion Representation Learning Based On Dynamic Graph [paper](https://ieeexplore.ieee.org/document/10447829)
- Leveraging Speech PTM, Text LLM, And Emotional TTS For Speech Emotion Recognition [paper](https://arxiv.org/pdf/2309.10294)
- Enhancing Two-Stage Finetuning for Speech Emotion Recognition Using Adapters [paper](https://ieeexplore.ieee.org/document/10446645)
- Frame-Level Emotional State Alignment Method for Speech Emotion Recognition [paper](https://arxiv.org/pdf/2312.16383) [code](https://github.com/ASolitaryMan/HFLEA) 
- Gradient-Based Dimensionality Reduction for Speech Emotion Recognition Using Deep Networks [paper](https://ieeexplore.ieee.org/document/10447616) [code](https://github.com/hxwangnus/Grad-based-Dim-Red-for-SER) 
- Speech Swin-Transformer: Exploring a Hierarchical Transformer with Shifted Windows for Speech Emotion Recognition [paper](https://arxiv.org/html/2401.10536v1)
- Disentanglement Network: Disentangle the Emotional Features from Acoustic Features for Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10448044)
- Improving Speaker-Independent Speech Emotion Recognition using Dynamic Joint Distribution Adaptation [paper](https://arxiv.org/html/2401.09752v1)
- Comparing data-Driven and Handcrafted Features for Dimensional Emotion Recognition [paper](https://publications.idiap.ch/attachments/papers/2024/Vlasenko_ICASSP_2024.pdf)
- Emotion-Aware Contrastive Adaptation Network for Source-Free Cross-Corpus Speech Emotion Recognition [paper](https://arxiv.org/html/2401.12925v1)
- Balancing Speaker-Rater Fairness for Gender-Neutral Speech Emotion Recognition [paper](https://www.researchgate.net/profile/Woan-Shiuan-Chien/publication/376799317_Balancing_Speaker-Rater_Fairness_For_Gender-Neutral_Speech_Emotion_Recognition/links/6589283d0bb2c7472b0d10ee/Balancing-Speaker-Rater-Fairness-For-Gender-Neutral-Speech-Emotion-Recognition.pdf)
- Prompting Audios Using Acoustic Properties for Emotion Representation [paper](https://arxiv.org/pdf/2310.02298)
- Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations [paper](https://arxiv.org/pdf/2309.04849)
- Generalization of Self-Supervised Learning-Based Representations for Cross-Domain Speech Emotion Recognition [paper](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Naini_2024.pdf)
- Dynamic Speech Emotion Recognition Using A Conditional Neural Process [paper](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Martinez-Lucas_2024.pdf)
- Revealing Emotional Clusters in Speaker Embeddings: A Contrastive Learning Strategy for Speech Emotion Recognition [paper](https://arxiv.org/pdf/2401.11017)
- Foundation Model Assisted Automatic Speech Emotion Recognition: Transcribing, Annotating, and Augmenting [paper](https://arxiv.org/pdf/2309.08108)
- MS-SENet: Enhancing Speech Emotion Recognition Through Multi-Scale Feature Fusion with Squeeze-and-Excitation Blocks [paper](https://arxiv.org/html/2312.11974v2)
- Cubic Knowledge Distillation for Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10447713) [code](https://github.com/Fly1toMoon/Cubic-Knowledge-Distillation)
- Improving Speech Emotion Recognition with Unsupervised Speaking Style Transfer [paper](https://arxiv.org/pdf/2211.08843)
- Emotion Neural Transducer for Fine-Grained Speech Emotion Recognition [paper](https://arxiv.org/pdf/2403.19224) [code](https://github.com/ECNU-Cross-Innovation-Lab/ENT) 
- Multi-Source Unsupervised Transfer Components Learning for Cross-Domain Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10446499)
- Self-Supervised Domain Exploration with an Optimal Transport Regularization for Open Set Cross-Domain Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10447482) 
- Towards Improving Speech Emotion Recognition Using Synthetic Data Augmentation from Emotion Conversion [paper](https://hal.science/hal-04364976/document)

##### conversation

- Esihgnn: Event-State Interactions Infused Heterogeneous Graph Neural Network for Conversational Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10447592)
- MCM-CSD: Multi-Granularity Context Modeling with Contrastive Speaker Detection for Emotion Recognition in Real-Time Conversation [paper](https://ieeexplore.ieee.org/document/10446410) [code](https://github.com/WHOISJENNY/MCM-CSD)
- SERC-GCN: Speech Emotion Recognition In Conversation Using Graph Convolutional Networks [paper](https://www.academia.edu/download/110735232/ICASSP_2024_1_.pdf)
- Conversation Clique-Based Model for Emotion Recognition In Conversation [paper](https://ieeexplore.ieee.org/document/10446226)
- Speaker-Centric Multimodal Fusion Networks for Emotion Recognition in Conversations [paper](https://ieeexplore.ieee.org/document/10447720)

##### Multimodal Speech（speech+text） 

- Large Language Model-Based Emotional Speech Annotation Using Context and Acoustic Feature for Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10448316)
- MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, Asr Error Detection, and Asr Error Correction [paper](https://arxiv.org/html/2401.13260v1)
- GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Accurate Speech Emotion Recognition [paper](https://arxiv.org/html/2306.07848v10) 

##### Multimodal

- Fine-Grained Disentangled Representation Learning For Multimodal Emotion Recognition [paper](https://arxiv.org/html/2312.13567v1)
- Improving Multi-Modal Emotion Recognition Using Entropy-Based Fusion and Pruning-Based Network Architecture Optimization [paper](https://ieeexplore.ieee.org/document/10447231)
- Multi-Grained Multimodal Interaction Network for Sentiment Analysis [paper](https://ieeexplore.ieee.org/document/10446351)
- Fusing Modality-Specific Representations and Decisions for Multimodal Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10447035)
- AttA-NET: Attention Aggregation Network for Audio-Visual Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10447640) [code](https://github.com/NariFan2002/AttA-NET)
- MMRBN: Rule-Based Network for Multimodal Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10447930) 
- Inter-Modality and Intra-Sample Alignment for Multi-Modal Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10446571)
- RL-EMO: A Reinforcement Learning Framework for Multimodal Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10446459) [code](https://github.com/zyh9929/RL-EMO) 
- Multi-Modal Emotion Recognition Using Multiple Acoustic Features and Dual Cross-Modal Transformer [paper](https://ieeexplore.ieee.org/document/10447830)

##### others

- AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models [paper](https://arxiv.org/pdf/2309.10787)

### 2023 papers

#### EMNLP2023

- Learning Language-guided Adaptive Hyper-modality Representation for Multimodal Sentiment Analysis [paper](https://arxiv.org/abs/2310.05804) [code](https://github.com/Haoyu-ha/ALMT)

#### NeurIPS 2023 

- Incomplete Multimodality-Diffused Emotion Recognition [paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/372cb7805eaccb2b7eed641271a30eec-Abstract-Conference.html)  [code](https://github.com/mdswyz/IMDer)

#### ACM MM 2023

- Emo-DNA: Emotion Decoupling and Alignment Learning for Cross-Corpus Speech Emotion Recognition [paper](https://arxiv.org/abs/2308.02190)
- Semi-Supervised Multimodal Emotion Recognition with Class-Balanced Pseudo-labeling [paper](https://dl.acm.org/doi/10.1145/3581783.3612864)

#### TPAMI 2023

- Dawn of the transformer era in speech emotion recognition: closing the valence gap [code](https://github.com/audeering/w2v2-how-to) [paper](https://arxiv.org/pdf/2203.07378)

#### InterSpeech 2023

##### Multimodal Speech（speech+text）

- LanSER: Language-Model Supported Speech Emotion Recognition [paper](https://arxiv.org/abs/2309.03978)
- Fine-tuned RoBERTa Model with a CNN-LSTM Network for Conversational Emotion [paper](https://www.isca-speech.org/archive/interspeech_2023/luo23_interspeech.html) 
- Emotion Label Encoding Using Word Embeddings for Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/stanley23_interspeech.html)
- Discrimination of the Different Intents Carried by the Same Text Through Integrating Multimodal Information [paper](https://www.isca-speech.org/archive/interspeech_2023/li23ia_interspeech.html)
- Meta-domain Adversarial Contrastive Learning for Alleviating Individual Bias in Self-sentiment Predictions [paper](https://www.isca-speech.org/archive/interspeech_2023/li23f_interspeech.html)
- SWRR: Feature Map Classifier Based on Sliding Window Attention and High-Response Feature Reuse for Multimodal Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/zhao23b_interspeech.html)
- Focus-attention-enhanced Crossmodal Transformer with Metric Learning for Multimodal Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/kim23c_interspeech.html)
- Learning Emotional Representations from Imbalanced Speech Data for Speech Emotion Recognition and Emotional Text-to-Speech [paper](https://www.isca-speech.org/archive/interspeech_2023/wang23ka_interspeech.html)
- MMER: Multimodal Multi-task Learning for Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/ghosh23b_interspeech.html)
- A Dual Attention-based Modality-Collaborative Fusion Network for Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/zhang23g_interspeech.html) [code](https://github.com/zxiaohen/ Speech-emotion-recognition-MCFN)
- Focus-attention-enhanced Crossmodal Transformer with Metric Learning for Multimodal Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/kim23c_interspeech.html)
- Speaker-aware Cross-modal Fusion Architecture for Conversational Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/zhao23e_interspeech.html)
- Emotion Prompting for Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/zhou23f_interspeech.html)
- EmotionNAS: Two-stream Neural Architecture Search for Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/sun23d_interspeech.html) *
- Leveraging Semantic Information for Efficient Self-Supervised Emotion Recognition with Audio-Textual Distilled Models [paper](https://www.isca-speech.org/archive/interspeech_2023/deoliveira23_interspeech.html)
- Leveraging Label Information for Multimodal Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/wang23ma_interspeech.html)
- Improving Joint Speech and Emotion Recognition Using Global Style Tokens [paper](https://www.isca-speech.org/archive/interspeech_2023/kyung23_interspeech.html)
- Dual Memory Fusion for Multimodal Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/prisayad23_interspeech.html) *

##### Speech

- Multi-Scale Temporal Transformer For Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/li23m_interspeech.html) *
- Speech Emotion Recognition by Estimating Emotional Label Sequences with Phoneme Class Attribute [paper](https://www.isca-speech.org/archive/interspeech_2023/nagase23_interspeech.html)
- Unsupervised Transfer Components Learning for Cross-Domain Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/jiang23_interspeech.html)
- Speech Emotion Recognition using Decomposed Speech via Multi-task Learning [paper](https://www.isca-speech.org/archive/interspeech_2023/hsu23_interspeech.html)

##### Others

- Cross-Lingual Cross-Age Adaptation for Low-Resource Elderly Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/cahyawijaya23_interspeech.html)
- MetricAug: A Distortion Metric-Lead Augmentation Strategy for Training Noise-Robust Speech Emotion [paper](https://www.isca-speech.org/archive/interspeech_2023/wu23c_interspeech.html)  [code](https://github.com/crowpeter/MetricAug) *
- Integrating Emotion Recognition with Speech Recognition and Speaker Diarisation for Conversations [paper](https://www.isca-speech.org/archive/interspeech_2023/wu23_interspeech.html)
- Two-stage Finetuning of Wav2vec 2.0 for Speech Emotion Recognition with ASR and Gender Pretraining [paper](https://www.isca-speech.org/archive/interspeech_2023/gao23d_interspeech.html)
- Diverse Feature Mapping and Fusion via Multitask Learning for Multilingual Speech Emotion Recognition [paper](https://www.isca-speech.org/archive/interspeech_2023/lee23g_interspeech.html)
- Hybrid Dataset for Speech Emotion Recognition in Russian Language [paper](https://www.isca-speech.org/archive/interspeech_2023/kondratenko23_interspeech.html)

#### ICASSP 2023

##### Multimodal Speech （speech+text）

- Exploring Complementary Features in Multi-Modal Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10096709)
- Cross-Modal Fusion Techniques for Utterance-Level Emotion Recognition from Text and Speech [paper](https://arxiv.org/abs/2302.02447)
- Using Auxiliary Tasks In Multimodal Fusion of Wav2vec 2.0 And Bert for Multimodal Emotion Recognition [paper](https://arxiv.org/abs/2302.13661)
- Robust multi-modal speech emotion recognition with ASR error adaptation [paper](https://ieeexplore.ieee.org/document/10094839)
- Multilevel Transformer for Multimodal Emotion Recognition [paper](https://arxiv.org/abs/2211.07711)
- MGAT: Multi-Granularity Attention Based Transformers for Multi-Modal Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10095855)
- Knowledge-Aware Bayesian Co-Attention for Multimodal Emotion Recognition [paper](https://arxiv.org/abs/2302.09856) 
- Exploiting Modality-Invariant Feature for Robust Multimodal Emotion Recognition with Missing Modalities [paper](https://arxiv.org/abs/2210.15359) [code](https://github.com/ZhuoYulang/IF-MMIN)
- Multimodal Emotion Recognition Based on Deep Temporal Features Using Cross-Modal Transformer and Self-Attention [paper](https://ieeexplore.ieee.org/document/10096937) [code](https://github.com/bubaimaji/cmt-mser)
- Exploring Attention Mechanisms for Multimodal Emotion Recognition in an Emergency Call Center Corpus [paper](https://arxiv.org/abs/2306.07115) 

##### Multimodal Speech-Visual

- Recursive Joint Attention for Audio-Visual Fusion in Regression Based Emotion Recognition [paper](https://arxiv.org/abs/2304.07958) [code](https://github.com/praveena2j/RecurrentJointAttentionwithLSTMs)
- Learning Cross-Modal Audiovisual Representations with Ladder Networks for Emotion Recognition [paper](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Goncalves_2023.pdf)

##### Speech

- DST: Deformable Speech Transformer for Emotion Recognition [paper](https://arxiv.org/abs/2302.13729) [code](https://github.com/HappyColor/DST)
- Multiple Acoustic Features Speech Emotion Recognition Using Cross-Attention Transformer [paper](https://ieeexplore.ieee.org/document/10095777)
- Speech Emotion Recognition Via Two-Stream Pooling Attention With Discriminative Channel Weighting [paper](https://ieeexplore.ieee.org/document/10095588)
- Speech Emotion Recognition via Heterogeneous Feature Learning [paper](https://ieeexplore.ieee.org/document/10095566)
- Pre-Trained Model Representations and Their Robustness Against Noise for Speech Emotion Analysis [paper](https://arxiv.org/abs/2303.03177)
- Learning Robust Self-Attention Features for Speech Emotion Recognition with Label-Adaptive Mixup [paper](https://arxiv.org/abs/2305.06273) [code](https://github.com/leitro/LabelAdaptiveMixup-SER)
- Hierarchical Network with Decoupled Knowledge Distillation for Speech Emotion Recognition [paper](https://arxiv.org/abs/2303.05134)
- Adapting a Self-Supervised Speech Representation for Noisy Speech Emotion Recognition by Using Contrastive Teacher-Student Learning [paper](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Leem_2023.pdf)
- Fast Yet Effective Speech Emotion Recognition with Self-Distillation [paper](https://arxiv.org/abs/2210.14636) [code](https://github.com/leibniz-future-lab/SelfDistill-SER)
- General or Specific? Investigating Effective Privacy Protection in Federated Learning for Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10096844)
- Speech-Based Emotion Recognition with Self-Supervised Models Using Attentive Channel-Wise Correlations and Label Smoothing [paper](https://arxiv.org/abs/2211.01756) [code](https://github.com/skakouros/s3prl_attentive_correlation)
- Temporal Modeling Matters: A Novel Temporal Emotional Modeling Approach for Speech Emotion Recognition [paper](https://arxiv.org/abs/2211.08233) [code](https://github.com/Jiaxin-Ye/TIM-Net_SER)
- Phonetic Anchor-Based Transfer Learning to Facilitate Unsupervised Cross-Lingual Speech Emotion Recognition [paper](https://ecs.utdallas.edu/research/researchlabs/msp-lab/publications/Upadhyay_2023.pdf)
- Knowledge Transfer for on-Device Speech Emotion Recognition With Neural Structured Learning [paper](https://arxiv.org/abs/2210.14977) [code](https://github.com/glam-imperial/NSL-SER)
- Speech Emotion Recognition Based on Low-Level Auto-Extracted Time-Frequency Features [paper](https://ieeexplore.ieee.org/document/10095260)
- Role of Lexical Boundary Information in Chunk-Level Segmentation for Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10096861)
- Zero-Shot Speech Emotion Recognition Using Generative Learning with Reconstructed Prototypes [paper](https://ieeexplore.ieee.org/document/10094888)
- A Generalized Subspace Distribution Adaptation Framework for Cross-Corpus Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10097258)
- exploring Wav2vec 2.0 Fine Tuning for Improved Speech Emotion Recognition [paper](https://arxiv.org/abs/2110.06309) [code](https://github.com/b04901014/FT-w2v2-ser)
- DWFormer: Dynamic Window Transformer for Speech Emotion Recognition [paper](https://arxiv.org/abs/2303.01694) [code](https://github.com/scutcsq/DWFormer)
- Deep Implicit Distribution Alignment Networks for cross-Corpus Speech Emotion Recognition [paper](https://arxiv.org/abs/2302.08921)
- Mingling or Misalignment? Temporal Shift for Speech Emotion Recognition with Pre-Trained Representations [paper](https://arxiv.org/abs/2302.13277) [code](https://github.com/ECNU-Cross-Innovation-Lab/ShiftSER)
- Designing and Evaluating Speech Emotion Recognition Systems: A Reality Check Case Study with IEMOCAP [paper](https://arxiv.org/abs/2304.00860)
- EMIX: A Data Augmentation Method for Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10096789)
- Multi-View Learning for Speech Emotion Recognition with Categorical Emotion, Categorical Sentiment, and Dimensional Scores [paper](https://ieeexplore.ieee.org/document/10096700)
- An Empirical Study and Improvement for Speech Emotion Recognition [paper](https://arxiv.org/abs/2304.03899) [code](https://github.com/Luyizhe/SpeechEmotion)
- Towards Learning Emotion Information from Short Segments of Speech [paper](https://ieeexplore.ieee.org/document/10095892)

##### Conversation

- Knowledge-Aware Graph Convolutional Network with Utterance-Specific Window Search for Emotion Recognition In Conversations [paper](https://ieeexplore.ieee.org/document/10095097)
- Multi-Scale Receptive Field Graph Model for Emotion Recognition in Conversations [paper](https://ieeexplore.ieee.org/document/10094596)
- SDTN: Speaker Dynamics Tracking Network for Emotion Recognition in Conversation [paper](https://ieeexplore.ieee.org/document/10094810)
- Emotion Recognition in Conversation from Variable-Length Context [paper](https://ieeexplore.ieee.org/document/10096161)

##### Other

- Ensemble Knowledge Distillation of Self-Supervised Speech Models [paper](https://arxiv.org/abs/2302.12757)
- Domain Adaptation without Catastrophic Forgetting on a Small-Scale Partially-Labeled Corpus for Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10096578)
- Shuffleaugment: A Data Augmentation Method Using Time Shuffling [paper](https://ieeexplore.ieee.org/document/10096927)
- Achieving Fair Speech Emotion Recognition via Perceptual Fairness [paper](https://www.researchgate.net/profile/Woan-Shiuan-Chien/publication/368719577_Achieving_Fair_Speech_Emotion_Recognition_via_Perceptual_Fairness/links/6455dcef97449a0e1a7dd51d/Achieving-Fair-Speech-Emotion-Recognition-via-Perceptual-Fairness.pdf)
- Unsupervised Domain Adaptation for Preference Learning Based Speech Emotion Recognition [paper](https://ieeexplore.ieee.org/document/10094301) 
- Using Emotion Embeddings to Transfer Knowledge between Emotions, Languages, and Annotation Formats [paper](https://arxiv.org/abs/2211.00171) [code](https://github.com/gchochla/Demux-MEmo) 
- QI-TTS: Questioning Intonation Control for Emotional Speech Synthesis [paper](https://ieeexplore.ieee.org/document/10095623)
- A Hierarchical Regression Chain Framework for Affective Vocal Burst Recognition [paper](https://arxiv.org/abs/2303.08027)

#### IJCAI 2023

- Mimicking the Thinking Process for Emotion Recognition in Conversation with Prompts and Paraphrasing [paper](https://arxiv.org/abs/2306.06601)

#### AAAI 2023

##### Conversation

- SKIER: A Symbolic Knowledge Integrated Model for Conversational Emotion Recognition [paper](https://ojs.aaai.org/index.php/AAAI/article/view/26541)
- BERT-ERC: Fine-Tuning BERT Is Enough for Emotion Recognition in Conversation [paper](https://ojs.aaai.org/index.php/AAAI/article/view/26582)

##### Other

- Feature Normalization and Cartography-Based Demonstrations for Prompt-Based Fine-Tuning on Emotion-Related Tasks [paper](https://ojs.aaai.org/index.php/AAAI/article/view/26514)

#### ACL 2023

##### Multimodal

- Layer-wise Fusion with Modality Independence Modeling for Multi-modal Emotion Recognition [paper](https://aclanthology.org/2023.acl-long.39/) [code](https://github.com/sunjunaimer/LFMIM)
- ConKI: Contrastive Knowledge Injection for Multimodal Sentiment Analysis [paper](https://aclanthology.org/2023.findings-acl.860/)
- ConFEDE: Contrastive Feature Decomposition for Multimodal Sentiment Analysis [paper](https://aclanthology.org/2023.acl-long.421/)
- Topic and Style-aware Transformer for Multimodal Emotion Recognition [paper](https://aclanthology.org/2023.findings-acl.130/)
- Self-adaptive Context and Modal-interaction Modeling For Multimodal Emotion Recognition [paper](https://aclanthology.org/2023.findings-acl.390/)
- QAP: A Quantum-Inspired Adaptive-Priority-Learning Model for Multimodal Emotion Recognition [paper](https://aclanthology.org/2023.findings-acl.772/)

##### Conversation

- Supervised Adversarial Contrastive Learning for Emotion Recognition in Conversations [paper](https://arxiv.org/abs/2306.01505) [code](https://github.com/zerohd4869/sacl)
- MultiEMO: An Attention-Based Correlation-Aware Multimodal Fusion Framework for Emotion Recognition in Conversations [paper](https://aclanthology.org/2023.acl-long.824/)
- DualGATs: Dual Graph Attention Networks for Emotion Recognition in Conversations [paper](https://aclanthology.org/2023.acl-long.408/)
- A Cross-Modality Context Fusion and Semantic Refinement Network for Emotion Recognition in Conversation [paper](https://aclanthology.org/2023.acl-long.732/)
- A Facial Expression-Aware Multimodal Multi-task Learning Framework for Emotion Recognition in Multi-party Conversations [paper](https://aclanthology.org/2023.acl-long.861/)

##### Other

- Label-Aware Hyperbolic Embeddings for Fine-grained Emotion Classification [paper](https://arxiv.org/abs/2306.14822) [code](https://github.com/dinobby/HypEmo)
- Estimating the Uncertainty in Emotion Attributes using Deep Evidential Regression [paper](https://arxiv.org/abs/2306.06760)



#### Other Conf / Journal

- Wen GYe SLi HWen PZhang Y(2023) Multimodal and Multitask Learning with Additive Angular Penalty Focus Loss for Speech Emotion RecognitionInternational Journal of Intelligent Systems https://dl.acm.org/doi/10.1155/2023/3662839
- Applying Segment-Level Attention on Bi-Modal Transformer Encoder for Audio-Visual Emotion Recognition, IEEE Transactions on Affective Computing https://dl.acm.org/doi/10.1109/TAFFC.2023.3258900
- Cross-corpus speech emotion recognition using subspace learning and domain adaption, EURASIP Journal on Audio, Speech, and Music Processing https://dl.acm.org/doi/10.1186/s13636-022-00264-5

### 2022 papers

#### AAAI 2022

##### Multimodal

- Tailor Versatile Multi-Modal Learning for Multi-Label Emotion Recognition [paper](https://ojs.aaai.org/index.php/AAAI/article/view/20895)

##### Conversation

- Hybrid Curriculum Learning for Emotion Recognition in Conversation [paper](https://ojs.aaai.org/index.php/AAAI/article/view/21413)
- Contrast and Generation Make BART a Good Dialogue Emotion Recognizer [paper](https://ojs.aaai.org/index.php/AAAI/article/view/21348)
- Is Discourse Role Important for Emotion Recognition in Conversation?  [paper](https://ojs.aaai.org/index.php/AAAI/article/view/21361)

#### IJCAI 2022

##### Speech

- CTL-MTNet: A Novel CapsNet and Transfer Learning-Based Mixed Task Net for Single-Corpus and Cross-Corpus Speech Emotion Recognition [paper](https://arxiv.org/abs/2207.10644) [code](https://github.com/MLDMXM2017/CTLMTNet)

##### Conversation

- Speaker-Guided Encoder-Decoder Framework for Emotion Recognition in Conversation [paper](https://arxiv.org/abs/2206.03173)
- CauAIN: Causal Aware Interaction Network for Emotion Recognition in Conversations [paper](https://www.ijcai.org/proceedings/2022/0628.pdf)

##### Other

- Online ECG Emotion Recognition for Unknown Subjects via Hypergraph-Based Transfer Learning [paper](https://www.ijcai.org/proceedings/2022/0509.pdf)

#### ACM MM 2022

##### Multimodal

- Counterfactual Reasoning for Out-of-distribution Multimodal Sentiment Analysis [paper](https://arxiv.org/abs/2207.11652)
- Unified Multi-modal Pre-training for Few-shot Sentiment Analysis with Prompt-based Learning [paper](https://dl.acm.org/doi/10.1145/3503161.3548306)

##### Vision

- Towards Unbiased Visual Emotion Recognition via Causal Intervention [paper](https://arxiv.org/abs/2107.12096)

##### Speech

- Unsupervised Domain Adaptation Integrating Transformer and Mutual Information for Cross-Corpus Speech Emotion Recognition [paper](https://dl.acm.org/doi/10.1145/3503161.3548328)

##### Other

- SER30K: A Large-Scale Dataset for Sticker Emotion Recognition [paper](https://dl.acm.org/doi/10.1145/3503161.3548407) [code](https://github.com/nku-shengzheliu/SER30K)

#### NAACL 2022

##### Multimodal

- COGMEN: COntextualized GNN based Multimodal Emotion recognitioN [paper](https://arxiv.org/abs/2205.02455) [code](https://github.com/exploration-lab/cogmen)

#### SLT 2022

- Multilingual Speech Emotion Recognition With Multi-Gating Mechanism and Neural Architecture Search [paper](https://arxiv.org/pdf/2211.08237)  [code](https://github.com/hannawong/Speech-Emotion-Recognition)



### 2021 papers

#### ICASSP 2021

- A NOVEL ATTENTION-BASED GATED RECURRENT UNIT AND ITS EFFICACY IN SPEECH EMOTION RECOGNITION
- A NOVEL END-TO-END SPEECH EMOTION RECOGNITION NETWORK WITH STACKED TRANSFORMER LAYERS
- COMPACT GRAPH ARCHITECTURE FOR SPEECH EMOTION RECOGNITION
- CONTRASTIVE UNSUPERVISED LEARNING FOR SPEECH EMOTION RECOGNITION
- CopyPaste: An Augmentation Method for Speech Emotion Recognition
- Cross-Corpus Speech Emotion Recognition Using Joint Distribution Adaptive Regression
- DeepEmoCluster: A Semi-Supervised Framework for Latent Cluster Representation of Speech Emotions
- DISENTANGLEMENT FOR AUDIO-VISUAL EMOTION RECOGNITION USING MULTITASK SETUP
- DOMAIN-ADVERSARIAL AUTOENCODER WITH ATTENTION BASED FEATURE LEVEL FUSION FOR SPEECH EMOTION RECOGNITION
- EEG-BASED EMOTION CLASSIFICATION USING GRAPH SIGNAL PROCESSING
- EFFICIENT SPEECH EMOTION RECOGNITION USING MULTI-SCALE CNN AND ATTENTION
- EMOTION RECOGNITION BY FUSING TIME SYNCHRONOUS AND TIME ASYNCHRONOUS REPRESENTATIONS
- HIERARCHICAL ATTENTION-BASED TEMPORAL CONVOLUTIONAL NETWORKS FOR EEG-BASED EMOTION RECOGNITION
- HIERARCHICAL NETWORK BASED ON THE FUSION OF STATIC AND DYNAMIC FEATURES FOR SPEECH EMOTION RECOGNITION
- LSSED: A LARGE-SCALE DATASET AND BENCHMARK FOR SPEECH EMOTION RECOGNITION
- LANGUAGE-SENSITIVE MUSIC EMOTION RECOGNITION MODELS: ARE WE REALLY THERE YET?
- MAEC: Multi-instance learning with an Adversarial Auto-encoder-based Classifier for Speech Emotion Recognition
- META-LEARNING FOR LOW-RESOURCE SPEECH EMOTION RECOGNITION
- MULTIMODAL CROSS- AND SELF-ATTENTION NETWORK FOR SPEECH EMOTION RECOGNITION
- MULTIMODAL EMOTION RECOGNITION WITH CAPSULE GRAPH CONVOLUTIONAL BASED REPRESENTATION FUSION
- Progressive Co-teaching for Ambiguous Speech Emotion Recognition
- REPRESENTATION LEARNING WITH SPECTRO-TEMPORAL-CHANNEL ATTENTION FOR SPEECH EMOTION RECOGNITION
- Speech Emotion Recognition based on Listener Adaptive Models
- SPEECH EMOTION RECOGNITION USING QUATERNION CONVOLUTIONAL NEURAL NETWORKS
- Speech Emotion Recognition using Semantic Information
- Speech Emotion Recognition with Multiscale Area Attention and Data Augmentation
- SUBJECT-INVARIANT EEG REPRESENTATION LEARNING FOR EMOTION RECOGNITION
- THE ROLE OF TASK AND ACOUSTIC SIMILARITY IN AUDIO TRANSFER LEARNING: INSIGHTS FROM THE SPEECH EMOTION RECOGNITION CASE

### 2021 papers

#### TASLP 2021

- Enhancing Segment-Based Speech Emotion Recognition by Iterative Self-Learning [paper](https://dl.acm.org/doi/abs/10.1109/taslp.2021.3133195)

### 2020 papers

#### AAAI 2020

##### Multimodal

- M3ER: Multiplicative Multimodal Emotion Recognition using Facial, Textual, and Speech Cues [paper](https://ojs.aaai.org/index.php/AAAI/article/view/5492)



### 2019 papers

Improved End-to-End Speech Emotion Recognition Using Self Attention Mechanism and Multitask Learning

Attention-Augmented End-to-End Multi-Task Learning for Emotion Prediction from Speech

### 2018 papers

#### InterSpeech

Predicting Arousal and Valence from Waveforms and Spectrograms using Deep Neural Networks

### 2017 papers

Jointly Predicting Arousal, Valence and Dominance with Multi-Task Learning

